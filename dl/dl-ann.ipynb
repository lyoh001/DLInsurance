{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install dabl\n",
    "# %pip install dtale\n",
    "# %pip install imblearn\n",
    "# %pip install keras-tuner\n",
    "# %pip install numpy\n",
    "# %pip install pandas\n",
    "# %pip install sklearn\n",
    "# %pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import shutil\n",
    "import warnings\n",
    "from pickle import dump\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from dabl import SimpleClassifier, SimpleRegressor, plot\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from IPython.display import display\n",
    "from keras_tuner.tuners import BayesianOptimization, Hyperband, RandomSearch\n",
    "from sklearn import set_config\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.datasets import (load_breast_cancer, load_diabetes, load_iris,\n",
    "                              load_wine)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectPercentile, chi2, f_classif\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import (RandomizedSearchCV, StratifiedKFold,\n",
    "                                     train_test_split)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "%matplotlib inline\n",
    "time_stamp = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "set_config(display=\"diagram\", print_changed_only=False)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "plt.rcParams[\"figure.figsize\"] = [12.8, 7.2]\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(device_lib.list_local_devices())\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n",
    "print(tf.test.gpu_device_name())\n",
    "!cat /proc/cpuinfo | grep \"model name\"\n",
    "!cat /proc/meminfo | grep \"MemTotal\"\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 11\n",
    "SEARCH = [\"hyperband\", \"random\", \"bayesian\"][0]\n",
    "EPOCHS = 500\n",
    "MAX_TRIALS = 20\n",
    "DUPLICATES = 0\n",
    "CLASSIFICATION = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, y_label = load_breast_cancer(as_frame=True)[\"frame\"], \"target\"\n",
    "df, y_label = load_iris(as_frame=True)[\"frame\"], \"target\"\n",
    "df, y_label = load_wine(as_frame=True)[\"frame\"], \"target\"\n",
    "df, y_label = load_diabetes(as_frame=True)[\"frame\"], \"target\"\n",
    "df, y_label = pd.read_csv(\"https://raw.githubusercontent.com/lyoh001/AzureDL/main/data/boston.csv\", delimiter=\",\"), \"MEDV\"\n",
    "df, y_label = pd.read_csv(\"https://raw.githubusercontent.com/lyoh001/AzureDL/main/data/titanic.csv\", delimiter=\",\"), \"Survived\"\n",
    "df, y_label = pd.read_csv(\"https://raw.githubusercontent.com/lyoh001/AzureDL/main/data/data.csv\", delimiter=\",\"), \"target\"\n",
    "\n",
    "print(f\"Current Shape: {df.shape}.\")\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(f\"Duplicates Percentage: {df.duplicated().sum() / df.shape[0] * 100:.2f}%\")\n",
    "if DUPLICATES:\n",
    "    print(f\"Duplicates have been kept {df.shape}.\")\n",
    "else:\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(f\"Duplicates have been removed {df.shape}.\")\n",
    "display(df.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"\"] = pd.to_datetime(df[\"\"], format=\"%d/%m/%Y %H:%M:%S\")\n",
    "# df[\"year\"] = df[\"\"].dt.year\n",
    "# df[\"month\"] = df[\"\"].dt.month\n",
    "# df[\"dayofweek\"] = df[\"\"].dt.dayofweek\n",
    "# df[\"dates\"] = (df[\"\"] - df[\"\"]).dt.days\n",
    "# df.replace({\"A\": 0, \"B\": 1, \"unknown\": np.nan}, inplace=True)\n",
    "# df[\"\"] = df[\"\"].map(lambda x: {\"\": 0, \"\": 1}.get(x, np.nan))\n",
    "# for col in [\"\"]:\n",
    "#     print(f\"col: {col}\")\n",
    "#     display(df[col][~df[col].map(lambda x: isinstance(x, (int, float)))])\n",
    "#     df[col] = df[col].str.strip()\n",
    "#     df[col] = df[col].map(pd.to_numeric)\n",
    "#     df[col] = df[col].astype(float)\n",
    "# df.drop([\"\"], inplace=True, axis=1)\n",
    "df.dropna(subset=[y_label], inplace=True)\n",
    "print(\"Data cleaning has been completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Current Shape: {df.shape}.\")\n",
    "df_info = pd.DataFrame(\n",
    "    {\n",
    "        \"column\": [col for col in df.columns],\n",
    "        \"dtype\": [f\"{df[col].dtype}\" for col in df.columns],\n",
    "        \"na\": [f\"{df[col].isna().sum()}\" for col in df.columns],\n",
    "        \"na %\": [f\"{round(df[col].isna().sum() / df[col].shape[0] * 100)}%\" for col in df.columns],\n",
    "        \"outliers\": [f\"{((df[col] < (df[col].quantile(0.25) - 1.5 * (df[col].quantile(0.75) - df[col].quantile(0.25)))) | (df[col] > (df[col].quantile(0.75) + 1.5 * (df[col].quantile(0.75) - df[col].quantile(0.25))))).sum()}\" if np.issubsctype(df[col].dtype, np.number) else \"n/a\" for col in df.columns],\n",
    "        \"outliers %\": [f\"{round((((df[col] < (df[col].quantile(0.25) - 1.5 * (df[col].quantile(0.75) - df[col].quantile(0.25)))) | (df[col] > (df[col].quantile(0.75) + 1.5 * (df[col].quantile(0.75) - df[col].quantile(0.25))))).sum()) / df[col].shape[0] * 100)}%\" if np.issubsctype(df[col].dtype, np.number) else \"n/a\" for col in df.columns],\n",
    "        \"skewness\": [f\"{df[col].skew(axis=0, skipna=True):.2f}\" if np.issubsctype(df[col].dtype, np.number) else \"n/a\" for col in df.columns],\n",
    "        \"corr\": [f\"{round(df[col].corr(other=df[y_label]) * 100)}%\" if np.issubsctype(df[col].dtype, np.number) else \"n/a\" for col in df.columns],\n",
    "        \"nunique\": [f\"{df[col].nunique()}\" for col in df.columns],\n",
    "        \"unique\": [df[col].unique() for col in df.columns],\n",
    "    }\n",
    ").sort_values(by=\"dtype\", ascending=False)\n",
    "display(df_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTLIERS = [\"keep\", \"cap\", \"log_transform\", \"drop\"][0]\n",
    "col_outlier = [col for col in df.columns if np.issubsctype(df[col].dtype, np.number) and col in [\"\"]]\n",
    "q1, q3 = df[col_outlier].quantile(0.25), df[col_outlier].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower_range, upper_range = q1 - (1.5 * iqr), q3 + (1.5 * iqr)\n",
    "condition = ~((df[col_outlier] < lower_range) | (df[col_outlier] > upper_range)).any(axis=1)\n",
    "print(f\"Current Shape: {df.shape}.\")\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(f\"Scanning for outliers in {col_outlier}.\")\n",
    "print(f\"Outliers Percentage: {(df.shape[0] - df[condition].shape[0]) / df.shape[0] * 100:.2f}%\")\n",
    "if OUTLIERS == \"keep\":\n",
    "    print(f\"Outliers have been kept {df.shape}.\")\n",
    "elif OUTLIERS == \"cap\":\n",
    "    for col in col_outlier:\n",
    "        df[col] = np.where(df[col] < lower_range[col], lower_range[col], df[col])\n",
    "        df[col] = np.where(df[col] > upper_range[col], upper_range[col], df[col])\n",
    "    print(f\"Outliers have been capped {df.shape}.\")\n",
    "elif OUTLIERS == \"log_transform\":\n",
    "    for col in col_outlier:\n",
    "        df[col] = np.log(df[col])\n",
    "    print(f\"Outliers have been log transformed {df.shape}.\")\n",
    "else:\n",
    "    df = df[condition]\n",
    "    print(f\"Outliers have been removed {df.shape}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Boxplots for Numeric Columns\")\n",
    "sns.boxplot(\n",
    "    data=df[[col for col in df.columns if np.issubsctype(df[col].dtype, np.number)]],\n",
    "    orient=\"h\",\n",
    "    color=\"steelblue\"\n",
    ")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), cmap=\"Blues\", fmt=\".2f\", annot=True, linewidths=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if np.issubsctype(df[col].dtype, np.number):\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "        sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "        sns.distplot(x=df[col], ax=ax[0], color=\"steelblue\", kde=True).set_xlabel(f\"{col}\")\n",
    "        sns.boxplot(x=df[col], ax=ax[1], color=\"steelblue\").set_xlabel(f\"{col}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLASSIFICATION:\n",
    "    for col in df.columns:\n",
    "        if np.issubsctype(df[col].dtype, np.number):\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "            sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "            sns.boxplot(x=y_label, y=col, data=df, color=\"steelblue\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.describe().round(2).T.style.background_gradient(cmap=\"Blues\"))\n",
    "display(df.quantile([0.01, 0.99]).T.style.background_gradient(cmap=\"Blues\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERSAMPLE = [\"none\", \"undersample\", \"oversample\", \"combine\"][0]\n",
    "X, y = df.drop(y_label, axis=1), df[y_label]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=[None, y, y][CLASSIFICATION],\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "col_oe = []\n",
    "preprocessor_oe = make_pipeline(\n",
    "    (SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (OrdinalEncoder(categories=[[\"no\", \"yes\"]])),\n",
    "    (MinMaxScaler()),\n",
    ")\n",
    "col_ohe = [\n",
    "    col\n",
    "    for col in X_train.columns\n",
    "    if np.issubsctype(X_train[col].dtype, np.object0)\n",
    "    and col not in col_oe\n",
    "    and X_train[col].nunique() <= 10\n",
    "]\n",
    "preprocessor_ohe = make_pipeline(\n",
    "    (SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\")),\n",
    ")\n",
    "col_num = [\n",
    "    col for col in X_train.columns if np.issubsctype(X_train[col].dtype, np.number)\n",
    "]\n",
    "preprocessor_num = make_pipeline(\n",
    "    (KNNImputer()),\n",
    "    (MinMaxScaler()),\n",
    ")\n",
    "preprocessor = make_column_transformer(\n",
    "    (preprocessor_oe, col_oe),\n",
    "    (preprocessor_ohe, col_ohe),\n",
    "    (preprocessor_num, col_num),\n",
    "    sparse_threshold=0\n",
    ")\n",
    "X_train_processed, y_train_processed = preprocessor.fit_transform(X_train), y_train\n",
    "X_test_processed, y_test_processed = preprocessor.transform(X_test), y_test\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(f\"total na %: {df.isnull().sum().sum() / np.product(df.shape) * 100:.2f}%\")\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(f\"col_oe: {col_oe}\")\n",
    "print(f\"col_ohe: {col_ohe}\")\n",
    "print(f\"col_num: {col_num}\")\n",
    "print(f\"total cols for preprocessor: {len(col_oe) + len(col_ohe) + len(col_num)}\")\n",
    "if CLASSIFICATION:\n",
    "    if OVERSAMPLE == \"undersample\":\n",
    "        X_train_processed, y_train_processed = RandomUnderSampler(random_state=RANDOM_STATE, sampling_strategy=\"not minority\").fit_resample(X_train_processed, y_train_processed)\n",
    "    elif OVERSAMPLE == \"oversample\":\n",
    "        X_train_processed, y_train_processed = SMOTE(random_state=RANDOM_STATE, sampling_strategy=\"not majority\").fit_resample(X_train_processed, y_train_processed)\n",
    "    elif OVERSAMPLE == \"combine\":\n",
    "        X_train_processed, y_train_processed = SMOTEENN(random_state=RANDOM_STATE, sampling_strategy=\"not majority\").fit_resample(X_train_processed, y_train_processed)\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3)\n",
    "    sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "    sns.despine(left=True)\n",
    "    sns.countplot(y, ax=ax[0], palette=\"Blues\").set_xlabel(\"y\")\n",
    "    sns.countplot(y_train, ax=ax[1], palette=\"Blues\").set_xlabel(\"y_train\")\n",
    "    sns.countplot(y_train_processed, ax=ax[2], palette=\"Blues\").set_xlabel(\"y_train_processed\")\n",
    "    plt.show()\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(f\"y:\\n{y.value_counts(normalize=True)}\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(f\"y_train:\\n{y_train.value_counts(normalize=True)}\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(f\"y_train_processed:\\n{y_train_processed.value_counts(normalize=True)}\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(f\"y_test:\\n{y_test.value_counts(normalize=True)}\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(f\"y_test_processed:\\n{y_test_processed.value_counts(normalize=True)}\")\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(f\"X: {X.shape}\\tX_train: {X_train.shape}\\tX_train_processed:{X_train_processed.shape}\\tX_test: {X_test.shape}\\t\\tX_test_processed:{X_test_processed.shape}\")\n",
    "print(f\"y: {y.shape}\\ty_train: {y_train.shape}\\t\\ty_train_processed:{y_train_processed.shape}\\ty_test: {y_test.shape}\\t\\ty_test_processed:{y_test_processed.shape}\")\n",
    "print(\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in col_oe + col_ohe:\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "    sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "    sns.despine(left=True)\n",
    "    sns.countplot(x=df[col], ax=ax[0], color=\"steelblue\", hue=df[y_label] if CLASSIFICATION else None).set_xlabel(f\"{col}\")\n",
    "    ax[1].pie(x=df[col].value_counts(), colors=sns.color_palette(\"Blues\"), autopct=\"%.1f%%\", shadow=True, labels=df[col].value_counts().index)\n",
    "    ax[1].set_title(col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(col_oe + col_ohe) >= 1 and len(col_num) >= 2:\n",
    "    sns.lineplot(data=df, x=col_num[0], y=col_num[1], hue=(col_oe + col_ohe)[0])\n",
    "    plt.title(f\"{col_num[0].capitalize()} index with {col_num[1].capitalize()}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue=y_label if CLASSIFICATION else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dtale\n",
    "# dtale.show(df)\n",
    "plot(X[col_num], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ml_model():\n",
    "    tests = [\n",
    "        {\n",
    "            \"model\": make_pipeline(\n",
    "                (preprocessor),\n",
    "                (SelectPercentile()),\n",
    "                (RandomForestClassifier()) if CLASSIFICATION else (LinearRegression()),\n",
    "            ),\n",
    "            \"params\": {\n",
    "                \"columntransformer__pipeline-3__knnimputer__n_neighbors\": [1, 3, 5, 7, 9],\n",
    "                \"selectpercentile__percentile\": [i * 10 for i in range(1, 10)],\n",
    "                \"selectpercentile__score_func\": [chi2, f_classif],\n",
    "                \"randomforestclassifier__n_estimators\": [100, 150, 200, 500],\n",
    "                \"randomforestclassifier__criterion\": [\"gini\", \"entropy\"],\n",
    "                \"randomforestclassifier__max_depth\": [5, 10, 20, 50, 100, 200],\n",
    "                \"randomforestclassifier__min_samples_split\": [2, 5, 10, 20, 50, 100, 200],\n",
    "                \"randomforestclassifier__min_samples_leaf\": [5, 10, 20, 50, 100, 200],\n",
    "                \"randomforestclassifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "            }\n",
    "            if CLASSIFICATION\n",
    "            else {\n",
    "                \"columntransformer__pipeline-3__knnimputer__n_neighbors\": [1, 3, 5, 7, 9],\n",
    "                \"selectpercentile__percentile\": [i * 10 for i in range(1, 10)],\n",
    "                \"selectpercentile__score_func\": [chi2, f_classif],\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "    for test in tests:\n",
    "        rscv = RandomizedSearchCV(\n",
    "            estimator=test[\"model\"],\n",
    "            param_distributions=test[\"params\"],\n",
    "            n_jobs=-1,\n",
    "            cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE)\n",
    "            if CLASSIFICATION\n",
    "            else 10,\n",
    "            scoring=\"accuracy\" if CLASSIFICATION else \"r2\",\n",
    "            n_iter=10,\n",
    "            return_train_score=True,\n",
    "        )\n",
    "        rscv.fit(X_train, y_train)\n",
    "        print(\"===train============================\")\n",
    "        print(f\"{rscv.best_score_ * 100:.2f}%\\n{test['model'][-1]}\\n{rscv.best_params_}\")\n",
    "        print(\"===params============================\")\n",
    "        display(pd.DataFrame(rscv.cv_results_).sort_values(by=\"rank_test_score\"))\n",
    "        print(\"===test============================\")\n",
    "        print(f\"test score:{rscv.score(X_test, y_test) * 100:.2f}%\")\n",
    "        print(\"====end===========================\\n\")\n",
    "\n",
    "    if CLASSIFICATION:\n",
    "        SimpleClassifier(random_state=RANDOM_STATE).fit(df, target_col=y_label)\n",
    "        print(\"-------------------------------------------------------\")\n",
    "        print(\n",
    "            classification_report(\n",
    "                y_test,\n",
    "                rscv.predict(X_test),\n",
    "            )\n",
    "        )\n",
    "        sns.heatmap(\n",
    "            tf.math.confusion_matrix(\n",
    "                y_test,\n",
    "                rscv.predict(X_test),\n",
    "            ),\n",
    "            cmap=\"Blues\",\n",
    "            fmt=\"d\",\n",
    "            annot=True,\n",
    "            linewidths=1,\n",
    "        )\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Truth\")\n",
    "\n",
    "    else:\n",
    "        SimpleRegressor(random_state=RANDOM_STATE).fit(df, target_col=y_label)\n",
    "        print(\"-------------------------------------------------------\")\n",
    "        print(\n",
    "            f\"r2: {r2_score(y_test, rscv.predict(X_test)):.3f} neg_mean_squared_error: -{mean_squared_error(y_test, rscv.predict(X_test)):_.3f}\"\n",
    "        )\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        sns.regplot(y_train, y_train, color=\"darkorange\", label=\"Truth\")\n",
    "        sns.regplot(\n",
    "            y_test,\n",
    "            rscv.predict(X_test),\n",
    "            color=\"darkcyan\",\n",
    "            label=\"Predicted\",\n",
    "        )\n",
    "        plt.title(\n",
    "            \"Truth vs Predicted\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "        plt.xlabel(\"Truth values\")\n",
    "        plt.ylabel(\"Predicted values\")\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.scatter(\n",
    "            rscv.predict(X_train),\n",
    "            rscv.predict(X_train) - y_train,\n",
    "            c=\"darkorange\",\n",
    "            marker=\"o\",\n",
    "            s=35,\n",
    "            alpha=0.5,\n",
    "            label=\"Train data\",\n",
    "        )\n",
    "        plt.scatter(\n",
    "            rscv.predict(X_test),\n",
    "            rscv.predict(X_test) - y_test,\n",
    "            c=\"darkcyan\",\n",
    "            marker=\"o\",\n",
    "            s=35,\n",
    "            alpha=0.7,\n",
    "            label=\"Test data\",\n",
    "        )\n",
    "        plt.title(\n",
    "            \"Predicted vs Residuals\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "        plt.xlabel(\"Predicted values\")\n",
    "        plt.ylabel(\"Residuals\")\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.hlines(y=0, xmin=0, xmax=df[y_label].max(), lw=2, color=\"red\")\n",
    "        plt.grid()\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        sns.distplot((y_train - rscv.predict(X_train)))\n",
    "        plt.title(\"Error Terms\")\n",
    "        plt.xlabel(\"Errors\")\n",
    "        plt.grid()\n",
    "\n",
    "    plt.show()\n",
    "    display(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"Truth\": y_test[:10].values,\n",
    "                \"Predicted\": rscv.predict(X_test[:10]).round(1),\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "def build_dl_model(hp):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "            units=hp.Int(\"input_00\", min_value=32, max_value=512, step=32),\n",
    "            input_shape=X_train_processed.shape[1:],\n",
    "        )\n",
    "    )\n",
    "    for i in range(1, hp.Int(\"num_layers\", min_value=2, max_value=64)):\n",
    "        model.add(\n",
    "            keras.layers.Dense(\n",
    "                units=hp.Int(f\"hidden_{i:02}\", min_value=32, max_value=512, step=32),\n",
    "                activation=\"relu\",\n",
    "            )\n",
    "        )\n",
    "        model.add(keras.layers.Dropout(hp.Float(\"dropout\", min_value=0, max_value=0.5, step=0.1)))\n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "            units=[1, 1, df[y_label].nunique()][CLASSIFICATION],\n",
    "            activation=[\"linear\", \"sigmoid\", \"softmax\"][CLASSIFICATION],\n",
    "        )\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])\n",
    "        ),\n",
    "        loss=[\"mean_squared_error\", \"binary_crossentropy\", \"sparse_categorical_crossentropy\"][CLASSIFICATION],\n",
    "        metrics=[\"mean_squared_error\", \"accuracy\", \"accuracy\"][CLASSIFICATION],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def get_result(epochs):\n",
    "    model = tuner.hypermodel.build(best_hps)\n",
    "    model.fit(\n",
    "        X_train_processed,\n",
    "        y_train_processed,\n",
    "        batch_size=256 if tf.config.list_physical_devices(\"GPU\") else 64,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.2,\n",
    "        verbose=1,\n",
    "    )\n",
    "    if CLASSIFICATION:\n",
    "        SimpleClassifier(random_state=RANDOM_STATE).fit(df, target_col=y_label)\n",
    "        print(\"-------------------------------------------------------\")\n",
    "        print(\n",
    "            classification_report(\n",
    "                y_test_processed,\n",
    "                [\n",
    "                    model.predict(X_test_processed).round(),\n",
    "                    np.argmax(model.predict(X_test_processed), axis=1),\n",
    "                ][CLASSIFICATION - 1],\n",
    "            )\n",
    "        )\n",
    "        sns.heatmap(\n",
    "            tf.math.confusion_matrix(\n",
    "                y_test_processed,\n",
    "                [\n",
    "                    model.predict(X_test_processed).round(),\n",
    "                    np.argmax(model.predict(X_test_processed), axis=1),\n",
    "                ][CLASSIFICATION - 1],\n",
    "            ),\n",
    "            cmap=\"Blues\",\n",
    "            fmt=\"d\",\n",
    "            annot=True,\n",
    "            linewidths=1,\n",
    "        )\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Truth\")\n",
    "\n",
    "    else:\n",
    "        SimpleRegressor(random_state=RANDOM_STATE).fit(df, target_col=y_label)\n",
    "        print(\"-------------------------------------------------------\")\n",
    "        print(f\"r2: {r2_score(y_test_processed, model.predict(X_test_processed).T[0]):.3f} neg_mean_squared_error: -{mean_squared_error(y_test_processed, model.predict(X_test_processed)):_.3f}\")\n",
    "    \n",
    "        plt.subplot(1, 3, 1)\n",
    "        sns.regplot(y_train_processed, y_train_processed, color=\"darkorange\", label=\"Truth\")\n",
    "        sns.regplot(\n",
    "            y_test_processed,\n",
    "            model.predict(X_test_processed).T[0],\n",
    "            color=\"darkcyan\",\n",
    "            label=\"Predicted\",\n",
    "        )\n",
    "        plt.title(\n",
    "            \"Truth vs Predicted\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "        plt.xlabel(\"Truth values\")\n",
    "        plt.ylabel(\"Predicted values\")\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.scatter(\n",
    "            model.predict(X_train_processed).T[0],\n",
    "            model.predict(X_train_processed).T[0] - y_train_processed,\n",
    "            c=\"darkorange\",\n",
    "            marker=\"o\",\n",
    "            s=35,\n",
    "            alpha=0.5,\n",
    "            label=\"Train data\",\n",
    "        )\n",
    "        plt.scatter(\n",
    "            model.predict(X_test_processed).T[0],\n",
    "            model.predict(X_test_processed).T[0] - y_test_processed,\n",
    "            c=\"darkcyan\",\n",
    "            marker=\"o\",\n",
    "            s=35,\n",
    "            alpha=0.7,\n",
    "            label=\"Test data\",\n",
    "        )\n",
    "        plt.title(\n",
    "            \"Predicted vs Residuals\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "        plt.xlabel(\"Predicted values\")\n",
    "        plt.ylabel(\"Residuals\")\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.hlines(y=0, xmin=0, xmax=df[y_label].max(), lw=2, color=\"red\")\n",
    "        plt.grid()\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        sns.distplot((y_train_processed - model.predict(X_train_processed).T[0]))\n",
    "        plt.title(\"Error Terms\")\n",
    "        plt.xlabel(\"Errors\")\n",
    "        plt.grid()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    display(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"Truth\": y_test_processed[:10].values,\n",
    "                \"Predicted\": [\n",
    "                    model.predict(X_test_processed[:10]).T[0],\n",
    "                    model.predict(X_test_processed[:10]).T[0].round(),\n",
    "                    np.argmax(model.predict(X_test_processed[:10]), axis=1),\n",
    "                ][CLASSIFICATION],\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    return model\n",
    "\n",
    "if SEARCH == \"hyperband\":\n",
    "    tuner = Hyperband(\n",
    "        build_dl_model,\n",
    "        objective=[\"val_mean_squared_error\", \"val_accuracy\", \"val_accuracy\"][CLASSIFICATION],\n",
    "        max_epochs=MAX_TRIALS,\n",
    "        factor=3,\n",
    "        directory=\".\",\n",
    "        project_name=\"keras_tuner\",\n",
    "        overwrite=True,\n",
    "    )\n",
    "elif SEARCH == \"random\":\n",
    "    tuner = RandomSearch(\n",
    "        build_dl_model,\n",
    "        objective=[\"val_mean_squared_error\", \"val_accuracy\", \"val_accuracy\"][CLASSIFICATION],\n",
    "        max_trials=MAX_TRIALS,\n",
    "        executions_per_trial=3,\n",
    "        directory=\".\",\n",
    "        project_name=\"keras_tuner\",\n",
    "        overwrite=True,\n",
    "    )\n",
    "else:\n",
    "    tuner = BayesianOptimization(\n",
    "        build_dl_model,\n",
    "        objective=[\"val_mean_squared_error\", \"val_accuracy\", \"val_accuracy\"][CLASSIFICATION],\n",
    "        max_trials=MAX_TRIALS,\n",
    "        executions_per_trial=3,\n",
    "        directory=\".\",\n",
    "        project_name=\"keras_tuner\",\n",
    "        overwrite=True,\n",
    "    )\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=int(MAX_TRIALS/4))\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tuner.search(\n",
    "    X_train_processed,\n",
    "    y_train_processed,\n",
    "    batch_size=256 if tf.config.list_physical_devices(\"GPU\") else 64,\n",
    "    callbacks=[early_stop],\n",
    "    epochs=MAX_TRIALS,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    ")\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(\n",
    "    X_train_processed,\n",
    "    y_train_processed,\n",
    "    batch_size=256 if tf.config.list_physical_devices(\"GPU\") else 64,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    ")\n",
    "val_per_epoch = history.history[\n",
    "    [\"val_mean_squared_error\", \"val_accuracy\", \"val_accuracy\"][CLASSIFICATION]\n",
    "]\n",
    "best_epoch = val_per_epoch.index([min(val_per_epoch), max(val_per_epoch), max(val_per_epoch)][CLASSIFICATION]) + 1\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[[\"mean_squared_error\", \"accuracy\", \"accuracy\"][CLASSIFICATION]], color='deeppink', linewidth=2.5)\n",
    "plt.plot(history.history[[\"val_mean_squared_error\", \"val_accuracy\", \"val_accuracy\"][CLASSIFICATION]], color='darkturquoise', linewidth=2.5)\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Training Accuracy\", \"Val Accuracy\"], loc=\"lower right\")\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"loss\"], color='deeppink', linewidth=2.5)\n",
    "plt.plot(history.history[\"val_loss\"], color='darkturquoise', linewidth=2.5)\n",
    "plt.title(\"Model Loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Training Loss\", \"Val Loss\"], loc=\"upper right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(f\"Best epoch: {best_epoch}\")\n",
    "model = get_result(best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_result(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_ml_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"dl_model_{time_stamp}\")\n",
    "shutil.make_archive(f\"dl_model_{time_stamp}\", \"zip\", f\"./dl_model_{time_stamp}\")\n",
    "dump(preprocessor, open(f\"dl_preprocessor.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# from pickle import load\n",
    "\n",
    "# import pandas as pd\n",
    "# from tensorflow import keras\n",
    "\n",
    "# df = pd.DataFrame(\n",
    "#     {\n",
    "#         \"\": [],\n",
    "#         \"\": [],\n",
    "#     }\n",
    "# )\n",
    "# shutil.unpack_archive(\"dl_model.zip\", \"dl_model\")\n",
    "# preprocessor = load(open(\"dl_preprocessor.pkl\", \"rb\"))\n",
    "# model = keras.models.load_model(\"dl_model\")\n",
    "# model.predict(preprocessor.transform(df))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
